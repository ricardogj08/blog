<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.8.1/github-markdown.min.css">
  <title>🦙 Ollama</title>
  <style>
    .markdown-body {
      box-sizing: border-box;
      min-width: 200px;
      max-width: 980px;
      margin: 0 auto;
      padding: 45px;
    }

    @media (max-width: 767px) {
      .markdown-body {
        padding: 15px;
      }
    }
  </style>
</head>
<body class="markdown-body">
  <header>
    <h1><a href="https://ricardogj08.github.io/blog/index.html">🐰 El Conejito Geek</a></h1>
    <p>Mi blog personal sobre GNU/Linux, software libre, programación, servidores y videojuegos.</p>
    <nav><a href="https://ricardogj08.github.io/blog/index.html">📢 Últimos artículos</a>
<a href="https://ricardogj08.github.io/blog/posts.html">📌 Artículos</a>
<a href="https://ricardogj08.github.io/blog/atom.xml">🔔 Feed</a>
<a href="https://notabug.org/ricardogj08/">🔗 Repositorio</a> <a href="https://ricardogj08.github.io/blog/personal/proyectos.html">🚀 Proyectos</a></nav>
  </header>
  <main>
    <h1>🦙 Ollama</h1>
<p>Es un software que permite instalar, configurar, ejecutar y gestionar <strong><em>modelos de lenguaje inteligente</em></strong>, el cual también es un programa que recopila una gran cantidad de información en texto para entender como funciona el lenguaje humano y poder generar predicciones o continuación de oraciones.</p>
<blockquote><p>Dicho de otra manera, <strong><em>inteligencia artificial</em></strong>.</p>
</blockquote>
<h2>Instalación</h2>
<ul>
<li>Puedes instalar <code>ollama</code> desde cualquier distribución GNU/Linux con el siguiente comando:</li>
</ul>
<pre><code>curl -fsSL https://ollama.com/install.sh | sh
</code></pre>
<blockquote><p>Probado correctamente en Slackware 15.0</p>
</blockquote>
<ul>
<li>Comprueba su instalación consultando la versión de <code>ollama</code> instalado:</li>
</ul>
<pre><code># Opción 1
ollama -v

# Opción 2
ollama --version
</code></pre>
<h2>Primeros pasos</h2>
<ul>
<li>Muestra un mensaje de ayuda acerca de los comandos disponibles:</li>
</ul>
<pre><code># Opción 1
ollama help

# Opción 2
ollama -h

# Opción 3
ollama --help
</code></pre>
<ul>
<li>Ejecuta el servicio o servidor de <code>ollama</code> (por defecto <code>127.0.0.1:11434</code>):</li>
</ul>
<pre><code>ollama serve
</code></pre>
<blockquote><p>Siempre debes ejecutar el servicio de <code>ollama</code> para utilizar cualquier modelo de lenguaje.</p>
</blockquote>
<ul>
<li>Instala y ejecuta un modelo de lenguaje:</li>
</ul>
<pre><code>ollama run MODELO

# Ejemplo
ollama run deepseek-r1:1.5b
</code></pre>
<blockquote><p>Puedes encontrar un listado completo de modelos de lenguaje soportados por <code>ollama</code>: <a href="https://ollama.com/search">https://ollama.com/search</a></p>
</blockquote>
<h2>Uso</h2>
<ul>
<li>Descarga e instala un modelo de lenguaje:</li>
</ul>
<pre><code>ollama pull MODELO

# Ejemplo
ollama pull deepseek-r1:1.5b
</code></pre>
<blockquote><p>Lo que se encuentra del lado derecho de los dos puntos <code>:</code> representa la versión o variante del modelo de lenguaje que selecciones.</p>
</blockquote>
<ul>
<li>Lista todos los modelos de lenguaje instalados en el equipo:</li>
</ul>
<pre><code># Opción 1
ollama list

# Opción 2
ollama ls
</code></pre>
<ul>
<li>Muestra información sobre un modelo de lenguaje instalado:</li>
</ul>
<pre><code>ollama show MODELO

# Ejemplo
ollama show deepseek-r1:1.5b
</code></pre>
<ul>
<li>Lista todos los modelos de lenguaje instalados en ejecución:</li>
</ul>
<pre><code>ollama ps
</code></pre>
<ul>
<li>Detiene la ejecución de un modelo de lenguaje instalado:</li>
</ul>
<pre><code>ollama stop MODELO

# Ejemplo
ollama stop deepseek-r1:1.5b
</code></pre>
<ul>
<li>Copia o duplica un modelo de lenguaje instalado:</li>
</ul>
<pre><code>ollama cp MODELO OTRO_MODELO

# Ejemplo
ollama cp deepseek-r1:1.5b mi_deepseek
</code></pre>
<blockquote><p>No afecta al modelo de lenguaje original instalado.</p>
</blockquote>
<ul>
<li>Elimina un modelo de lenguaje instalado:</li>
</ul>
<pre><code>ollama rm MODELO

# Ejemplo
ollama rm deepseek-r1:1.5b
</code></pre>
<ul>
<li>Crea o importa un modelo de lenguaje personalizado a través de un archivo (por defecto <code>Modelfile</code>):</li>
</ul>
<pre><code>ollama create MI_MODELO

# También
ollama create MI_MODELO -f Modelfile
</code></pre>
<ul>
<li>Permite compartir un modelo lenguaje en un servidor remoto (por defecto <code>127.0.0.1:11434</code>):</li>
</ul>
<pre><code>ollama push MI_MODELO
</code></pre>
<blockquote><p>Permite compartir tus propios modelos de lenguaje con otras personas.</p>
<p>Más información en: <a href="https://github.com/ollama/ollama/blob/main/docs/import.md#Sharing-your-model-on-ollamacom">https://github.com/ollama/ollama/blob/main/docs/import.md#Sharing-your-model-on-ollamacom</a></p>
</blockquote>
<h2>Referencias</h2>
<ul>
<li><a href="https://ollama.com/">Sitio web oficial de Ollama.</a></li>
<li><a href="https://github.com/ollama/ollama">Repositorio oficial de Ollama.</a></li>
</ul>
  </main>
  <hr>
  <footer>
    <p>CC-BY-4.0 - Ricardo García Jiménez &lt;ricardogj08@riseup.net&gt;</p>
    <p>Generated with <a href="https://notabug.org/ricardogj08/ssgs" target="_blank">ssgs</a>, a simple static blog generator written in POSIX sh.</p>
  </footer>
</body>
</html>
